{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import calendar\n",
    "import time \n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check up \n",
    "https://stackoverflow.com/users/2901002/jezrael"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: New York Times; font-size: 1em; color: green;\">\n",
    "    \n",
    "The most important part of the Pandas library is the DataFrame. A DataFrame holds the type of data you might think of as a table. This is similar to a sheet in Excel, or a table in a SQL database. \n",
    "\n",
    "Want to know the basic usage look like this?\n",
    "\n",
    "* [pandas source](https://github.com/pandas-dev/pandas)\n",
    "* [19 Essential Snippets in Pandas](https://jeffdelaney.me/blog/useful-snippets-in-pandas/)\n",
    "* https://towardsdatascience.com/pandas-dataframe-a-lightweight-intro-680e3a212b96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tupList = [[('commentID', 'commentText', 'date'), ('123456', 'blahblahblah', '2019')], [('45678', 'hello world', '2018'), ('0', 'text', '2017')]]\n",
    "pd.DataFrame(sum(tupList,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Tom':['1','1','1','1','1','0','0'],\n",
    "        'John':['1','1','1','1','1','0','0'],\n",
    "        'Harry':['1','1','1','1','1','0','0'],\n",
    "        'Bob':['1','1','1','1','1','0','0']}\n",
    "\n",
    "df1 = pd.DataFrame.from_dict(data, orient='index',\n",
    "                        columns=['Day 1','Day 2','Day 3','Day 4','Day 5','Day 6','Day 7',])\n",
    "\n",
    "print(df1)\n",
    "\n",
    "\n",
    "data2 = {'Name':['Tom','Harry'], 'Day':['Day 7','Day 6']}\n",
    "df2 = pd.DataFrame.from_dict(data2)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count row numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame({'Lat': [20, 30], 'Lon':[20,10]})\n",
    "[{'lat': df.loc[i, 'Lat'], 'lon' : df.loc[i, 'Lon']} for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zip(df['Lat'].tolist(), df['Lon'].tolist())\n",
    "[{'lat': a, 'lon': b} for a, b in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})\n",
    "df.columns = ['a', 'b']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57822783/merging-sublists-into-columns-with-a-loop/57822938#57822938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[11, 22, 33], [44, 55, 66]]\n",
    "b = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "data = [x+y for x, y in zip(a,b)]\n",
    "df = pd.DataFrame(data).T\n",
    "df.columns = ['a', 'b']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new columns to existed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"column_1\": [1] , \"column_2\": [2] , \"column_3\": [3] })\n",
    "print(df)\n",
    "A = 1\n",
    "B = \"c_10\"\n",
    "df.insert(0,'A',A)\n",
    "df.insert(1,'B',B)\n",
    "print(df.to_string(index= False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57120458/pivot-datetime-index-to-a-start-and-end-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv', sep=r'\\s{2,}', engine='python')\n",
    "n = len(df.index)//2\n",
    "x = df['datetime']\n",
    "# drop the column of 'datetime'\n",
    "df = df.drop('datetime', axis=1)\n",
    "# Remove the duplicated row\n",
    "df = df.drop_duplicates()\n",
    "df.index=range(n) \n",
    "start = x[0::2]\n",
    "start.index=range(n)\n",
    "end = x[1::2]\n",
    "end.index = range(n)\n",
    "df['start'] =start \n",
    "df['end']=end \n",
    "#df.style.set_properties(**{'text-align': 'left'})\n",
    "print(df.to_string(index=False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'customerId' : ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B','B', 'B', 'B'],\n",
    "    'startOf15Min' : ['2019-07-30T00:00:00', '2019-07-30T00:15:00',\n",
    "       '2019-07-30T07:00:00', '2019-07-30T07:15:00',\n",
    "       '2019-07-30T07:30:00', '2019-07-30T07:45:00',\n",
    "       '2019-07-30T08:00:00', '2019-07-30T00:00:00',\n",
    "       '2019-07-30T00:15:00', '2019-07-30T06:30:00',\n",
    "       '2019-07-30T06:45:00', '2019-07-30T07:00:00',\n",
    "       '2019-07-30T07:15:00', '2019-07-30T07:30:00',\n",
    "       '2019-07-30T07:45:00', '2019-07-30T08:00:00']\n",
    "}, columns=['customerId', 'startOf15Min'])\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [1, 3, 4]\n",
    "df = pd.DataFrame(np.random.rand(10, 5))\n",
    "df[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas find missing 15 minutes intervals\n",
    "https://stackoverflow.com/questions/57267868/pandas-find-missing-15-minutes-intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'customerId' : ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B','B', 'B', 'B'],\n",
    "    'startOf15Min' : ['2019-07-30T00:00:00', '2019-07-30T00:15:00',\n",
    "       '2019-07-30T07:00:00', '2019-07-30T07:15:00',\n",
    "       '2019-07-30T07:30:00', '2019-07-30T07:45:00',\n",
    "       '2019-07-30T08:00:00', '2019-07-30T00:00:00',\n",
    "       '2019-07-30T00:15:00', '2019-07-30T06:30:00',\n",
    "       '2019-07-30T06:45:00', '2019-07-30T07:00:00',\n",
    "       '2019-07-30T07:15:00', '2019-07-30T07:30:00',\n",
    "       '2019-07-30T07:45:00', '2019-07-30T08:00:00']\n",
    "}, columns=['customerId', 'startOf15Min'])\n",
    "\n",
    "df.startOf15Min = pd.to_datetime(df.startOf15Min)\n",
    "\n",
    "intv = pd.date_range('2019-07-30 06:00:00','2019-07-30 09:00:00', freq='15Min', closed='left')\n",
    "df.startOf15Min = pd.to_datetime(df.startOf15Min)\n",
    "missing = df.groupby('customerId')['startOf15Min'].apply(lambda x: [i for i in intv if i not in x])\n",
    "\n",
    "print(missing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57549162/filling-in-missing-hours-in-a-pandas-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/57533004/how-to-drop-all-rows-in-pandas-dataframe-with-negative-values/57533045?noredirect=1#comment101531645_57533045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict0 = {\n",
    "    \"country\":\n",
    "    [\"Brazil\", \"Russia\", \"India\", \"China\", \"South Africa\", \"South Africa\"],\n",
    "    \"capital\":\n",
    "    [\"Brasilia\", \"Moscow\", \"New Dehli\", \"Beijing\", \"Pretoria\", \"Pretoria\"],\n",
    "    \"area\": [8.516, 171.10, 3.286, 9.597, 1.221, 1.221],\n",
    "    \"population\": [200.4, 143.5, 1252, 1357, 52.98, 52.98]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict0)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'col1': [1, 2, 3, 4],\n",
    "    'col2': [-1, -2, 3, 4],\n",
    "    'col3': ['a', 'b', 'c', 'd'],\n",
    "    'col4': [1, 2, 3, 4]\n",
    "})\n",
    "df[df.select_dtypes(include=[np.number]).ge(0).all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57588176/creating-new-list-names-during-iteration-to-append-elements/57588483#57588483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"R1\": [8,2,3], \"R2\": [-21,-24,4], \"R3\": [-9,46,6]})\n",
    "df.apply(lambda row: row[:])\n",
    "# desired Output\n",
    "list1 = df.values[0].tolist()\n",
    "print(list1)\n",
    "list2 = df.values[1].tolist()\n",
    "print(list2)\n",
    "list3 = df.values[2].tolist()\n",
    "print(list3)\n",
    "#df.loc[1].values.tolist()\n",
    "for i in range(3):\n",
    "    print('list{} = {}'.format(i, df.loc[i].values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57772483/converting-dataframe-column-values-to-list/57772563#57772563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Column': [[\"a\", \"b\", \"c\"],[\"a\"], 'a','b',[\"cc\", \"dd\"]]})\n",
    "print(df[df.Column.apply(lambda row: type(row)==list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df.loc` and `df.iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict0 = {\n",
    "    \"country\":\n",
    "    [\"Brazil\", \"Russia\", \"India\", \"China\", \"South Africa\", \"South Africa\"],\n",
    "    \"capital\":\n",
    "    [\"Brasilia\", \"Moscow\", \"New Dehli\", \"Beijing\", \"Pretoria\", \"Pretoria\"],\n",
    "    \"area\": [8.516, 171.10, 3.286, 9.597, 1.221, 1.221],\n",
    "    \"population\": [200.4, 143.5, 1252, 1357, 52.98, 52.98]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict0)\n",
    "df.head(2) \n",
    "df.index[df.country==\"South Africa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'country']\n",
    "df['country']\n",
    "df.iloc[-5:]\n",
    "df.iloc[[1,2]]\n",
    "df.iloc[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(list(df.index.values), 3)[-2:]\n",
    "df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "df = pd.DataFrame(np.random.randint(10, size=(1000, 2)))\n",
    "df.columns = ['x', 'y']\n",
    "indices = np.random.choice(df.index[-50:], size=5, replace=False)\n",
    "result = df.iloc[indices]\n",
    "print(result)\n",
    "\n",
    "def randomly_generated_dataframe( df, n1, n2): \n",
    "    selected_indices = random.sample(list(df.index.values), n1)[-n2:]\n",
    "    return df.iloc[selected_indices]\n",
    "\n",
    "randomly_generated_dataframe( df, 5, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df.drop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
    "        'year': [2012, 2012, 2013, 2014, 2014], \n",
    "        'reports': [4, 24, 31, 2, 3]}\n",
    "df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n",
    "df\n",
    "df.drop(['Cochice', 'Pima'])\n",
    "df.drop('reports', axis=1)\n",
    "df[df.name != 'Tina']\n",
    "df.drop(df.index[[2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57807305/pandas-drop-duplicates-in-cola-keeping-row-based-on-condition-on-colb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['A', 'A', 'A','B','B'], 'col2': ['type1', 'type2', 'type1', 'type2', 'type1'] , 'hour': ['18:03:30','18:00:48', '18:13:46', '18:11:29', '18:06:31']  })\n",
    "df \n",
    "df.drop_duplicates(['col1','col2']) \n",
    "df.drop_duplicates(['col1','col2'], keep= 'last') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57823131/decomposing-complex-data-structure-consisting-of-dictionary-and-list-of-tuples-tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'S37_1': [('L26_1', '100.000'), ('S13_1', '100.000'), ('L29_1', '100.000'), ('S37_1', '100.000'), ('S38_1', '99.910'), ('L25_1', '99.910'), ('L16_1', '99.888')],\\\n",
    "        'L29_1': [('L26_1', '100.000'), ('S13_1', '100.000'), ('L29_1', '100.000'), ('S37_1', '100.000'), ('S38_1', '99.910'), ('L25_1', '99.910'), ('L16_1', '99.888')], \\\n",
    "        'L25_2': [('S38_3', '100.000'), ('L16_4', '100.000'), ('L25_2', '100.000'), ('L29_3', '99.889'), ('L26_2', '99.783'), ('S13_2', '99.777'), ('S37_2', '99.464')], \\\n",
    "        'S38_3': [('S38_3', '100.000'), ('L16_4', '100.000'), ('L25_2', '100.000'), ('L29_3', '99.889'), ('L26_2', '99.783'), ('S13_2', '99.777'), ('S37_2', '99.464')]}\n",
    "\n",
    "df = pd.DataFrame(test)\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge 2 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= {'id' : [1,1,1,3,5,6,7,8,9,10], 'name' : ['a','a','a','c','e','f','g','h','i','j']}\n",
    "df2 = {'id' : [1,2,3,4,5,6,7,8,9,10], 'age' : [21,11,45,11,56,22,26,26,17,32], 'gender' : ['M','M','f','f','M','f','M','M','f','M']}}\n",
    "df1 = pd.DataFrame(df1)\n",
    "df1.set_index('id', inplace = True)\n",
    "df2 = pd.DataFrame(df2)\n",
    "df2.set_index('id', inplace = True)\n",
    "df1['gender'] = df2['gender']\n",
    "#df1.merge(df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict0 = {'CO2': {'GWP': 1.0, 'B_index': [23, 92, 93, 427, 437, 438]}, 'CH4': {'GWP': 28.0, 'B_index': [24, 67, 68, 69, 70, 71, 72, 73, 74, 426, 435]}, 'N2O': {'GWP': 265.0, 'B_index': [25, 429]}}\n",
    "df = pd.DataFrame(dict0)\n",
    "print(df.loc['B_index'])\n",
    "print(df.loc['B_index', \"CO2\"])\n",
    "print(df.loc['B_index', \"CH4\"])\n",
    "print(df.loc['B_index', \"N2O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-1][1]\n",
    "df.iloc[0][1] \n",
    "df.loc[\"GWP\":, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {\n",
    "    \"Column1\": [\n",
    "        \"A1-19\", \"B2-52\", \"C3-1245Â¯main_123456789\", \"D4\", \"Z89028\",\n",
    "        \"F7Â¯main_123456789\"\n",
    "    ]\n",
    "}\n",
    "df1 = pd.DataFrame(dict1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.compile(r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"New\"]=df1['Column1'].str.split('Â¯main_').str[0]\n",
    "df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'C3-1245Â¯main_123456789'.split(\"Â¯main_\")\n",
    "'Z89028'.split(\"Â¯main_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ['x', 'y', 'z', 'a', 'b', 'c']\n",
    "m = np.array(m)\n",
    "print(type(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57687415/merge-two-dataframe-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "left = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': np.random.randn(4)})    \n",
    "right = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': np.random.randn(4)})\n",
    "left\n",
    "right\n",
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57780410/join-multiple-columns-into-one-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['column 1', 'column 2', 'column 3'], data = [['17.1 g', np.nan, np.nan], [np.nan, '7.0 g', np.nan], [np.nan, '3.7 g', '0.7 g'], [np.nan, np.nan, '1.7 g'], ['1.1 g', np.nan, '1.0 g']])\n",
    "df \n",
    "df.bfill(axis=1).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join between "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57823020/how-to-concat-between-columns-keeping-sequence-unchanged-in-2-dataframes-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\n",
    "    'index': [0, 1, 2, 3],\n",
    "    '394': ['Recycle Gas', 'TT', 'nan', 'nan'],\n",
    "    'min': ['min', 'date', '2011-03-02 08:00:00', '2011-03-02 08:00:00'],\n",
    "    'FIC-2000': ['20K20', 'kg/h', '-20.7', '-27.5 ']\n",
    "}\n",
    "data2 = {\n",
    "    'index': [0],\n",
    "    'Unnamed:0': ['Service'],\n",
    "    '0': ['Prop'],\n",
    "    '1': ['Prop1'],\n",
    "    '394': 'Recycle Gas',\n",
    "    '395': ['RecG']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "df1\n",
    "pd.merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a column and based on conditions\n",
    "* https://stackoverflow.com/questions/57129328/for-loop-based-on-two-filtered-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {\"Actual\":[1,0], \"Predicted\" :[1,1], \"A\":  [0.002753, 0.909696], \"B\": [0.997247, 0.090304]}\n",
    "df = pd.DataFrame(dict1)\n",
    "df \n",
    "df.iloc[1,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(df.index):\n",
    "    if df.loc[i,\"Actual\"] ==df.loc[i,\"Predicted\"]==0 or df.loc[i,\"Actual\"] ==df.loc[i,\"Predicted\"]==1:\n",
    "        df.loc[i, \"Conf_Type\"] = True\n",
    "    else:\n",
    "        df.loc[i, \"Conf_Type\"] = False\n",
    "df     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.filter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),index=['mouse', 'rabbit'], columns=['one', 'two', 'three'])\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(items=['one', 'three'])\n",
    "df.filter(regex='e$', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df[col_name].mask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57806725/converting-an-empty-row-into-a-columns-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = pd.DataFrame({'A':['John','ex1','ex2','Joe','qz1','qz2','qz3'],\n",
    "                 'val1':[ '',10,5,'',80,10,10],\n",
    "                  'val2':[ '',20,6,'',90,10,1],\n",
    "                  'val3':[ '',30,7,'',100,10,0]})\n",
    "#x_df.loc[:,'val1':'val3'].apply(lambda row: row == '').any(1) \n",
    "\n",
    "#x_df.filter(like='val').ne('').any(1)\n",
    "\n",
    "s = x_df.filter(like='val').ne('').any(1)\n",
    "x_df['A'].mask(s)\n",
    "# mask(s) selects the empty rows\n",
    "x_df['name'] = x_df['A'].mask(s).ffill()\n",
    "x_df\n",
    "# filter\n",
    "x_df[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.index` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/57121550/finding-the-best-match-for-similar-texts-and-keeping-only-unique-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Project_Name\": [\"Hilton International\", \"Hilton International A\"]}\n",
    "df2 = pd.DataFrame(data)\n",
    "df2.index = range(552, 554)\n",
    "for i in df2.index:\n",
    "    df2.loc[[i]][\"Project_Name\"]\n",
    "\n",
    "#df2.loc[[553]] = \"Hilton International\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.apply` `lambda`\n",
    "https://stackoverflow.com/questions/57551081/elegant-way-to-format-datetime-values-without-using-datetime-functions-in-pandas#57551081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def str2time(x):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(x, '%m/%d/%Y %H:%M:%S %p')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "df1_new['obs_date'] = df1_new['obs_date'].apply(str2time)\n",
    "print(df1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Month':[1,1,2,2], 'Year':[2013, 2013, 2013, 2013]})\n",
    "#print(df.to_string(index=False))\n",
    "df['Date'] =  df.apply(lambda row: '1' + '/' + str(row.Month) + '/'+ str(row.Year), axis = 1)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from haversine import haversine\n",
    "x = {'city':['AUSTRALIAN NATIONAL UNIVERSITY', 'BARTON', 'DARWIN', 'DARWIN', 'PARAP', 'ALAWA', 'BRINKIN', 'CASUARINA', 'JINGILI', 'LEE_POINT' ]}\n",
    "la = {'Latitude':[-35.277272,-35.201372, -12.801028 , -12.801028, -12.432181, -12.378451, -12.367769, -12.376597, -12.385761, -12.360865]}\n",
    "lo = {'Longitude':[149.117136,149.095065, 130.955789 , 130.955789, 130.843310,  130.877014, 130.869808, 130.850489, 130.873726, 130.891349]}\n",
    "data = {**x, **la, **lo}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop_duplicates()\n",
    "city = list(df[\"city\"])\n",
    "TwoCity = list(itertools.combinations(city, 2))\n",
    "df1 = pd.DataFrame({'TwoCity':TwoCity})\n",
    "#df['Date'] =  df.apply(lambda row: '1' + '/' + str(row.Month) + '/'+ str(row.Year), axis = 1)\n",
    "df1['Distance'] = df1.apply(lambda row: \\\n",
    "          haversine((df[df['city']==row.TwoCity[0]]['Latitude'], df[df['city']==row.TwoCity[0]]['Longitude']),\\\n",
    "                    (df[df['city']==row.TwoCity[1]]['Latitude'], df[df['city']==row.TwoCity[1]]['Longitude'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'description': ['XG154LU', '4562689', '556', 'LE896E', '65KKL4']}\n",
    "def convert(v):\n",
    "    if any([char.isalpha() for char in v]):\n",
    "        va = [char for char in v if char.isalpha()]\n",
    "        va = ''.join(va)\n",
    "        return va\n",
    "    else:\n",
    "        return v\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "df['description'] = df['description'].apply(convert)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57789813/how-to-avoid-20-if-statements-when-applying-function-to-pandas-based-on-a-city/57790298#57789813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'name': ['jim', 'jon'],\n",
    "    'city': ['new york', ''],\n",
    "    'county': ['', 'los angeles']\n",
    "})\n",
    "\n",
    "df['region'] = df['city'] + df['county']\n",
    "table = {\n",
    "    'new york': 'abc123',\n",
    "    'chicago': 'abc124',\n",
    "    'los angeles': 'abc125',\n",
    "    'miami': 'abc126'\n",
    "}\n",
    "df['region'] = df.region.apply(lambda row: table[row])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df.applymap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57517483/how-to-select-rows-within-two-dates-in-a-pandas-dataframe#57517527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1':['xxx;#2;yyy','aaa;#3;bbbccc '],'col2':['zzz;#46;zyzcz','bbbb;cccc;dd#5'  ]})\n",
    "def cleanDigit(row):\n",
    "    replacements = [('\\d', ''), ('#', ''), (';;', ';')]\n",
    "    for (old, new) in replacements:\n",
    "        row = re.sub(old, new, row)\n",
    "    return row\n",
    "df[['col1', 'col2']] = df[['col1', 'col2']].applymap(cleanDigit)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "df5 = pd.DataFrame({'text':[[['some','string'],['yes']],[['hello','how','are','u'],['fine','thanks']]],\n",
    "               'names':[[['chris'],['peter','kate']],[['steve','john'],['kyle','eric']]]})\n",
    "\n",
    "print(df5.applymap(lambda x: list(chain.from_iterable(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(chain.from_iterable([['some','string', ['ok', ['okk']]],['yes']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57107125/remove-duplicates-from-python-dataframe-list#57107125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: list(dict.fromkeys(ast.literal_eval(x)))\n",
    "df['newlist'] = df['text_lemmatized'].map(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df.col_name.str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement it with pandas \n",
    "raw_data = {'ID': [1,2,3,4,5,6,7,8,9,10], 'body': ['FITrnXS$100', '$1000rnReason', 'rnIf', 'bevlauedrnrnnext', 'obccrnrnnoncrnrnactionrn', 'rnrnnotification', 'insdrnrnnon', 'rnrnupdated', 'rnreason', 'rnrnrnLOR']}\n",
    "remove_string =['rn', 'rnr', 'rnrn', 'rnrnrn']\n",
    "df = pd.DataFrame(raw_data, columns = ['ID', 'body', 'cleaned_txt', 'Removed_string'])\n",
    "df \n",
    "df['cleaned_txt'], df['Removed_string'] = df['body'], df['body']\n",
    "for i in remove_string[::-1]:\n",
    "    df['cleaned_txt'] = df['cleaned_txt'].str.replace(i, ' ')\n",
    "    df[i] = df['Removed_string'].str.extract('({})'.format(i)) \n",
    "\n",
    "df['Removed_string'] = df[remove_string].ffill(axis=1).iloc[:, -1]\n",
    "df = df.drop(remove_string, axis=1)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement it in original data ðŸ‘Œ\n",
    "raw_data = {'ID': [1,2,3,4,5,6,7,8,9,10], \n",
    "        'body': ['FITrnXS$100', '$1000rnReason', 'rnIf', 'bevlauedrnrnnext', 'obccrnrnnoncrnrnactionrn', 'rnrnnotification', 'insdrnrnnon', 'rnrnupdated', 'rnreason', 'rnrnrnLOR']}\n",
    "removed_string =['rn', 'rnr', 'rnrn', 'rnrnrn']\n",
    "removed_string =  removed_string[::-1]\n",
    "\n",
    "raw_data['Removed_string'] = []\n",
    "raw_data['cleaned_txt'] = []\n",
    "for i in raw_data['body']:\n",
    "    j = 0\n",
    "    m = removed_string[j]\n",
    "    while True:\n",
    "        m = removed_string[j]\n",
    "        pattern = re.compile(m)\n",
    "        n = pattern.findall(i)\n",
    "        if len(n) != 0: \n",
    "            raw_data['cleaned_txt'].append(i.replace(m, ' '))\n",
    "            raw_data['Removed_string'].append(m)\n",
    "            break\n",
    "        j += 1\n",
    "df = pd.DataFrame(raw_data, columns = ['ID', 'body', 'cleaned_txt', 'Removed_string'])\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## len().value_count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\":[\"a\", \"b\", \"aa\", \"aaa\", \"bbb\", \"a\"]})\n",
    "df.id.str.len().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge  drop duplication \n",
    "https://stackoverflow.com/questions/57406428/pandas-merge-df-many-to-many-without-duplicates/57406653#57406653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {\n",
    "    \"a\": [0,0,1,2],\n",
    "    \"b\": [3,3,4,5],\n",
    "    \"c\": [6,7,8,9]\n",
    "}\n",
    "df1 = pd.DataFrame(data_dic)\n",
    "\n",
    "data_dic = {\n",
    "    \"a\": [0,0,1,2],\n",
    "    \"b\": [3,3,4,5],\n",
    "    \"d\": [10,10,12,13]\n",
    "}\n",
    "df2 = pd.DataFrame(data_dic)\n",
    "\n",
    "\n",
    "df3 = pd.merge(df1, df2, how='inner', on=['a', 'b']).drop_duplicates()\n",
    "df3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([df1, df2], axis=1).T.drop_duplicates().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57604212/how-to-split-a-list-of-dictionaries-into-multiple-columns-keeping-the-same-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.explode`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53218931/how-to-unnest-explode-a-column-in-a-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'score': [1,2,3], \n",
    "        'tags': [['apple','pear','guava'],['truck','car','plane'],['cat','dog','mouse']]}\n",
    "df = pd.DataFrame(raw_data, columns = ['score', 'tags'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "for i in raw_data['tags']:\n",
    "    for j in i:\n",
    "        k.append(j )\n",
    "k \n",
    "raw_data['tags'] = k \n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dictionary or list inside a column into separate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57800262/convert-a-column-with-a-list-of-dicts-where-column-name-and-value-are-both-pres/57800449?noredirect=1#comment102033530_57800449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col1':100, 'col2': 200, 'col3': [{'attribute': 'Pattern', 'value': 'Printed'},\n",
    " {'attribute': 'Topwear style', 'value': 'T shirt'},\n",
    " {'attribute': 'Bottomwear Length', 'value': 'Short'},\n",
    " {'attribute': 'Colour Palette', 'value': 'Bright colours'},\n",
    " {'attribute': 'Bottomwear style', 'value': 'Baggy'},\n",
    " {'attribute': 'Topwear length', 'value': 'Waist'},\n",
    " {'attribute': 'Sleeve style', 'value': 'Sleeveless'},\n",
    " {'attribute': 'Type of pattern', 'value': 'Graphic print'},\n",
    " {'attribute': 'Neck', 'value': 'Round'},\n",
    " {'attribute': 'Level of embellishment', 'value': 'No'}]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "x = df['col3'].tolist()\n",
    "newcol = {item['attribute'] : [item['value']] for item in x }\n",
    "newdf = pd.DataFrame(newcol)\n",
    "del df['col3'] \n",
    "print(df.join(newdf, how='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `groupby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.geeksforgeeks.org/adding-new-column-to-existing-dataframe-in-pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```md\n",
    "datetime               transmission #\n",
    "2019-07-12 00:03:06    124\n",
    "2019-07-12 00:04:56    124\n",
    "2019-07-12 00:20:10    125\n",
    "2019-07-12 00:21:33    125\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'testid': 'testid_1', 'value':15},\n",
    "{'testid': 'testid_1', 'value':15},\n",
    "{'testid': 'testid_1', 'value':20},\n",
    "{'testid': 'testid_1', 'value':20},\n",
    "{'testid': 'testid_1', 'value':15},\n",
    "{'testid': 'testid_1', 'value':15},\n",
    "{'testid': 'testid_2', 'value':215},\n",
    "{'testid': 'testid_2', 'value':215},\n",
    "{'testid': 'testid_3', 'value':215},\n",
    "{'testid': 'testid_3', 'value':69},\n",
    "{'testid': 'testid_3', 'value':215}]\n",
    "\n",
    "df = pd.DataFrame(data) \n",
    "df \n",
    "df['newid']=df.groupby('testid').value.apply(lambda x : x.diff().ne(0).cumsum()) \n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57802242/python-group-by-column-and-select-by-hierarchy#57802362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col-a':[1,1,1,2,2,3,3],'col-b': [None, 'Failed', 'Passed', 'None', 'Passed', 'Inconclusive', 'Passed']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "d = {'Failed':0,'Inconclusive':1, 'Passed':2, None: 3}\n",
    "df['new'] = df['col-b'].map(d)\n",
    "df = df.sort_values(['col-a', 'new']).drop_duplicates('col-a').drop('new', 1)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57829530/how-to-split-the-csv-based-on-multiple-columns#57829530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'Header1': ['Alpha', 'Alpha', 'Beta', 'Beta', 'Beta', 'Gamma'],\n",
    "    'Header2': [\n",
    "        'energy', 'energy', 'energy_imbalance', 'energy', 'energy',\n",
    "        'energy_imbalance'\n",
    "    ],\n",
    "    'Header3': [0.1, 0.34, 0.66, 0.7, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df \n",
    "\n",
    "list(df.groupby(['Header1','Header2']))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `diff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([11,15,22,27,36,69,77])\n",
    "s.diff().fillna(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.Series.dt.total_seconds`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57814695/formating-time-difference-in-dataframe-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'request':['REQ0079455','REQ0079455'] ,'Req_Created':['15/05/2019  16:51', '15/05/2019 16:51'], 'Req_Closed': ['23/05/2019 20:53','23/05/2019 20:53']   \n",
    "}     \n",
    "df = pd.DataFrame(data)\n",
    "df \n",
    "\n",
    "df['Req_time_taken'] = pd.to_datetime(df['Req_Closed'], format ='%d/%m/%Y %H:%M') - pd.to_datetime(df['Req_Created'], format ='%d/%m/%Y %H:%M') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Req_time_taken'].dt.total_seconds().apply(lambda x: '%s hours %s minutes' % (x//3600, x%3600/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57822431/duplicate-rows-in-a-value-range-of-a-dataframe#57822485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df.index.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'A.low': [1, 1, 2],\n",
    "    'A.up': [3, 2, 4],\n",
    "    'B': [1, 2, 1],\n",
    "    'C': ['D', 'E', 'E']\n",
    "}\n",
    "df = pd.DataFrame(data, )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"col1\" : [\"a\", \"b\", \"z\",\"w\", \"g\", \"p\", \"f\"], \"col2\" : \n",
    "[\"010\", \"030\",\"500\",\"333\",\"090\",\"050\",\"111\"]})\n",
    "data['col2'] = data['col2'].apply(lambda x:re.sub(r\"^0\", '', x))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57509388/how-to-extract-value-from-an-array-based-on-condition-in-pandas-or-numpy#57509518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Bird':['Parrot','Eagle','Seagull'],'Color':[['Light_Blue','Green','Dark_Blue'],['Sky_Blue','Black','White', 'Yellow','Gray'],['White','Jet_Blue','Pink', 'Tan','Brown', 'Purple']]}\n",
    "df =pd.DataFrame( data) \n",
    "df[\"Blue\"]=df.Color.apply(lambda x: [v for v in x if \"Blue\" not in v])\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57549300/extract-limited-set-of-date-patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "data = pd.DataFrame({\"col1\" : [\"a\", \"b\", \"z\",\"w\", \"g\", \"p\", \"f\"], \"col2\" : \n",
    "[\"010\", \"030\",\"500\",\"333\",\"090\",\"050\",\"111\"]})\n",
    "data.head(2)\n",
    "\n",
    "pattern =  re.compile(r'^0+')\n",
    "for i, v in enumerate(data[\"col2\"]):\n",
    "    data[\"col2\"][i]=pattern.sub(\"\", v)  \n",
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'color':[['Light_Blue','Green','Dark_Blue'], ['Sky_Blue','Black','White', 'Yellow','Gray'],['White','Jet_Blue','Pink', 'Tan','Brown', 'Purple']]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "[[i for i in r if not i.endswith(tuple(['_Blue', '_']))] for r in df.color]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57808480/how-to-apply-the-regex-on-pandas-dataframe-column-having-string-representation-o#57808565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.color.apply(lambda row: [x for x in row if not x.endswith(tuple(['_Blue', '_']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/57263555/dataframe-resample-does-not-include-last-datam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2020-01-01',  periods=12, freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Date':['2020-01-01', '2021-01-01', '2022-01-01', '2023-01-01'],\\\n",
    "                   'Value':[1.248310e+06, 1.259511e+06, 1.276312e+06,1.298714e+06]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range('1/1/2020', periods=4, freq='YS')\n",
    "series = pd.Series([1.248310e+06, 1.259511e+06, 1.276312e+06, 1.298714e+06], index=index)\n",
    "series2 = pd.Series(1.298714e+06, pd.date_range('12/1/2023', periods=1))\n",
    "series = series.append(series2)\n",
    "down_sampling = series.resample('MS').ffill()\n",
    "down_sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/57507399/how-to-divide-60-mins-datapoints-into-15-mins#57507518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Time' :['2016-01-01 00:00:00','2016-01-01 01:00:00','2016-01-01 02:00:00 '], 'A':[1,5,13]})\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range('2016-01-01 00:00:00', periods=4, freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Time': [\"2016-01-01 00:00:00\", \"2016-01-01 01:00:00\", \"2016-01-01 02:00:00\"],\n",
    "    'A': [1 , 5, 13]\n",
    "})\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "new_idx = pd.DatetimeIndex(start=df['Time'].iloc[0], end=df['Time'].iloc[-1], freq='15min')\n",
    "df2 = df.set_index('Time').reindex(new_idx).interpolate().reset_index()\n",
    "df2.rename(columns={'index': 'Time'}, inplace=True)\n",
    "df2['A'] = df2['A'].round().astype(int)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['temp'] = pd.date_range(start='01-Jan-2000', end='31-Dec-2018', freq='MS')  \n",
    "df['value'] = 5\n",
    "df.set_index('temp', inplace=True)\n",
    "df['days_in_month'] = df.index.daysinmonth \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to save styled pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Diego', 'Luis', 'Vidal', 'John', 'Yusef']\n",
    "id = ['b000000005', 'b000000015', 'b000000002', 'b000000011', 'b000000013']\n",
    "cel = [7878, 6464, 1100, 4545, 1717]\n",
    "date = pd.to_datetime(['2017-05-31 20:53:00', '2017-05-11 20:53:00', '2017-05-08 20:53:00', \n",
    "                       '2017-06-06 20:53:00', '2017-06-06 20:53:00'])\n",
    "\n",
    "df = pd.DataFrame({'Name':name,'ID':id,'Cel':cel,'Date':date})\n",
    "\n",
    "def color(val):\n",
    "    if val < datetime.now():\n",
    "        color = 'green'\n",
    "    elif val > datetime.now():\n",
    "        color = 'yellow'\n",
    "    elif val > (datetime.now() + timedelta(days=60)):\n",
    "        color = 'red'\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "df = df.style.applymap(color, subset=['Date'])\n",
    "# https://mode.com/example-gallery/python_dataframe_styling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.apply(borders) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html = df.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataFrame.html', 'a') as f:\n",
    "    f.write(df.render() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "176.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
