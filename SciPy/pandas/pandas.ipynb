{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:20:44.216156Z",
     "start_time": "2019-12-30T13:20:44.213091Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:20:50.377551Z",
     "start_time": "2019-12-30T13:20:44.428701Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:20:50.388395Z",
     "start_time": "2019-12-30T13:20:50.382571Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import calendar\n",
    "import time \n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check up \n",
    "https://stackoverflow.com/users/2901002/jezrael"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: New York Times; font-size: 1em; color: green;\">\n",
    "    \n",
    "The most important part of the Pandas library is the DataFrame. A DataFrame holds the type of data you might think of as a table. This is similar to a sheet in Excel, or a table in a SQL database. \n",
    "\n",
    "Want to know the basic usage look like this?\n",
    "\n",
    "* https://github.com/pandas-dev/pandas\n",
    "* [19 Essential Snippets in Pandas](https://jeffdelaney.me/blog/useful-snippets-in-panda)\n",
    "* https://pbpython.com\n",
    "* http://www.datasciencemadesimple.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T03:15:16.127496Z",
     "start_time": "2019-12-21T03:15:16.094234Z"
    }
   },
   "outputs": [],
   "source": [
    "list_tuple = [('commentID', 'commentText', 'date'),\n",
    "              ('123456', 'blahblahblah', '2019'),\n",
    "              ('45678', 'hello world', '2018'), ('0', 'text', '2017')]\n",
    "df = pd.DataFrame(list_tuple)\n",
    "df.index = ['I', 'II', 'III','IV']\n",
    "\n",
    "# Rename column \n",
    "df.columns = list_tuple[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T02:32:00.776106Z",
     "start_time": "2019-12-21T02:32:00.742812Z"
    }
   },
   "outputs": [],
   "source": [
    "list_tuple = [('commentID', 'commentText', 'date'),\n",
    "              ('123456', 'blahblahblah', '2019'),\n",
    "              ('45678', 'hello world', '2018'), ('0', 'text', '2017')]\n",
    "pd.DataFrame.from_records(list_tuple[1:], index = list_tuple[0])\n",
    "pd.DataFrame.from_records(list_tuple[1:], columns = list_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T02:38:59.222276Z",
     "start_time": "2019-12-21T02:38:59.200003Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {'Tom':['1','1','1','1','1','0','0'],\n",
    "        'John':['1','1','1','1','1','0','0'],\n",
    "        'Harry':['1','1','1','1','1','0','0'],\n",
    "        'Bob':['1','1','1','1','1','0','0']}\n",
    "# When using the â€˜indexâ€™ orientation, the column names can be specified manually:\n",
    "df1 = pd.DataFrame.from_dict(data, orient='index',\n",
    "                        columns=['Day 1','Day 2','Day 3','Day 4','Day 5','Day 6','Day 7',])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count row numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T02:38:49.243815Z",
     "start_time": "2019-12-21T02:38:49.185562Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Lat': [20, 30], 'Lon':[20,10]})\n",
    "df \n",
    "[{'lat': df.loc[i, 'Lat'], 'lon' : df.loc[i, 'Lon']} for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zip(df['Lat'].tolist(), df['Lon'].tolist())\n",
    "[{'lat': a, 'lon': b} for a, b in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new columns to existed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T03:25:10.689181Z",
     "start_time": "2019-12-21T03:25:10.656157Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"column_1\": [1], \"column_2\": [2], \"column_3\": [3]})\n",
    "df\n",
    "A = 1\n",
    "B = \"c_10\"\n",
    "df.insert(0, 'A', A)\n",
    "df.insert(2, 'B', B)\n",
    "df\n",
    "#df.to_string(index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57120458/pivot-datetime-index-to-a-start-and-end-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T03:28:39.035471Z",
     "start_time": "2019-12-21T03:28:38.997163Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv', sep=r'\\s{2,}', engine='python')\n",
    "df\n",
    "\n",
    "n = len(df.index)//2\n",
    "x = df['datetime']\n",
    "# drop the column of 'datetime'\n",
    "df = df.drop('datetime', axis=1)\n",
    "\n",
    "\n",
    "# Remove the duplicated row\n",
    "df = df.drop_duplicates()\n",
    "df.index=range(n) \n",
    "start = x[0::2]\n",
    "start.index=range(n)\n",
    "end = x[1::2]\n",
    "end.index = range(n)\n",
    "df['start'] =start \n",
    "df['end']=end \n",
    "#df.style.set_properties(**{'text-align': 'left'})\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'customerId' : ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B','B', 'B', 'B'],\n",
    "    'startOf15Min' : ['2019-07-30T00:00:00', '2019-07-30T00:15:00',\n",
    "       '2019-07-30T07:00:00', '2019-07-30T07:15:00',\n",
    "       '2019-07-30T07:30:00', '2019-07-30T07:45:00',\n",
    "       '2019-07-30T08:00:00', '2019-07-30T00:00:00',\n",
    "       '2019-07-30T00:15:00', '2019-07-30T06:30:00',\n",
    "       '2019-07-30T06:45:00', '2019-07-30T07:00:00',\n",
    "       '2019-07-30T07:15:00', '2019-07-30T07:30:00',\n",
    "       '2019-07-30T07:45:00', '2019-07-30T08:00:00']\n",
    "}, columns=['customerId', 'startOf15Min'])\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [1, 3, 4]\n",
    "df = pd.DataFrame(np.random.rand(10, 5))\n",
    "df[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas find missing 15 minutes intervals\n",
    "https://stackoverflow.com/questions/57267868/pandas-find-missing-15-minutes-intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'customerId' : ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B','B', 'B', 'B'],\n",
    "    'startOf15Min' : ['2019-07-30T00:00:00', '2019-07-30T00:15:00',\n",
    "       '2019-07-30T07:00:00', '2019-07-30T07:15:00',\n",
    "       '2019-07-30T07:30:00', '2019-07-30T07:45:00',\n",
    "       '2019-07-30T08:00:00', '2019-07-30T00:00:00',\n",
    "       '2019-07-30T00:15:00', '2019-07-30T06:30:00',\n",
    "       '2019-07-30T06:45:00', '2019-07-30T07:00:00',\n",
    "       '2019-07-30T07:15:00', '2019-07-30T07:30:00',\n",
    "       '2019-07-30T07:45:00', '2019-07-30T08:00:00']\n",
    "}, columns=['customerId', 'startOf15Min'])\n",
    "\n",
    "df.startOf15Min = pd.to_datetime(df.startOf15Min)\n",
    "\n",
    "intv = pd.date_range('2019-07-30 06:00:00','2019-07-30 09:00:00', freq='15Min', closed='left')\n",
    "df.startOf15Min = pd.to_datetime(df.startOf15Min)\n",
    "missing = df.groupby('customerId')['startOf15Min'].apply(lambda x: [i for i in intv if i not in x])\n",
    "\n",
    "print(missing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57549162/filling-in-missing-hours-in-a-pandas-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/57533004/how-to-drop-all-rows-in-pandas-dataframe-with-negative-values/57533045?noredirect=1#comment101531645_57533045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict0 = {\n",
    "    \"country\":\n",
    "    [\"Brazil\", \"Russia\", \"India\", \"China\", \"South Africa\", \"South Africa\"],\n",
    "    \"capital\":\n",
    "    [\"Brasilia\", \"Moscow\", \"New Dehli\", \"Beijing\", \"Pretoria\", \"Pretoria\"],\n",
    "    \"area\": [8.516, 171.10, 3.286, 9.597, 1.221, 1.221],\n",
    "    \"population\": [200.4, 143.5, 1252, 1357, 52.98, 52.98]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict0)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'col1': [1, 2, 3, 4],\n",
    "    'col2': [-1, -2, 3, 4],\n",
    "    'col3': ['a', 'b', 'c', 'd'],\n",
    "    'col4': [1, 2, 3, 4]\n",
    "})\n",
    "df[df.select_dtypes(include=[np.number]).ge(0).all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57588176/creating-new-list-names-during-iteration-to-append-elements/57588483#57588483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"R1\": [8,2,3], \"R2\": [-21,-24,4], \"R3\": [-9,46,6]})\n",
    "df.apply(lambda row: row[:])\n",
    "# desired Output\n",
    "list1 = df.values[0].tolist()\n",
    "print(list1)\n",
    "list2 = df.values[1].tolist()\n",
    "print(list2)\n",
    "list3 = df.values[2].tolist()\n",
    "print(list3)\n",
    "#df.loc[1].values.tolist()\n",
    "for i in range(3):\n",
    "    print('list{} = {}'.format(i, df.loc[i].values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57772483/converting-dataframe-column-values-to-list/57772563#57772563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Column': [[\"a\", \"b\", \"c\"],[\"a\"], 'a','b',[\"cc\", \"dd\"]]})\n",
    "print(df[df.Column.apply(lambda row: type(row)==list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df.loc` and `df.iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:06:56.347465Z",
     "start_time": "2019-12-21T04:06:56.321204Z"
    }
   },
   "outputs": [],
   "source": [
    "dict0 = {\n",
    "    \"country\":\n",
    "    [\"Brazil\", \"Russia\", \"India\", \"China\", \"South Africa\", \"South Africa\"],\n",
    "    \"capital\":\n",
    "    [\"Brasilia\", \"Moscow\", \"New Dehli\", \"Beijing\", \"Pretoria\", \"Pretoria\"],\n",
    "    \"area\": [8.516, 171.10, 3.286, 9.597, 1.221, 1.221],\n",
    "    \"population\": [200.4, 143.5, 1252, 1357, 52.98, 52.98]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict0)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:10:17.712623Z",
     "start_time": "2019-12-21T04:10:17.562373Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:,'country']\n",
    "df['country']\n",
    "df.iloc[-5:]\n",
    "df.iloc[[1,2]]\n",
    "df.iloc[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:12:00.428744Z",
     "start_time": "2019-12-21T04:12:00.188904Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "df = pd.DataFrame(np.random.randint(10, size=(1000, 2)))\n",
    "df.columns = ['x', 'y']\n",
    "indices = np.random.choice(df.index[-50:], size=5, replace=False)\n",
    "result = df.iloc[indices]\n",
    "print(result)\n",
    "\n",
    "def randomly_generated_dataframe( df, n1, n2): \n",
    "    selected_indices = random.sample(list(df.index.values), n1)[-n2:]\n",
    "    return df.iloc[selected_indices]\n",
    "\n",
    "randomly_generated_dataframe( df, 5, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df.drop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:04:56.733446Z",
     "start_time": "2019-12-21T04:04:56.350127Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
    "        'year': [2012, 2012, 2013, 2014, 2014], \n",
    "        'reports': [4, 24, 31, 2, 3]}\n",
    "df = pd.DataFrame(data, index = ['Cochice', 'Pima', 'Santa Cruz', 'Maricopa', 'Yuma'])\n",
    "df\n",
    "df.drop(['Cochice', 'Pima'])\n",
    "df.drop('reports', axis=1)\n",
    "df[df.name != 'Tina']\n",
    "df.drop(df.index[[2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57807305/pandas-drop-duplicates-in-cola-keeping-row-based-on-condition-on-colb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:12:19.490891Z",
     "start_time": "2019-12-21T04:12:19.398742Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['A', 'A', 'A','B','B'], 'col2': ['type1', 'type2', 'type1', 'type2', 'type1'] , 'hour': ['18:03:30','18:00:48', '18:13:46', '18:11:29', '18:06:31']  })\n",
    "df \n",
    "df.drop_duplicates(['col1','col2']) \n",
    "df.drop_duplicates(['col1','col2'], keep= 'last') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge 2 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T06:34:35.018246Z",
     "start_time": "2019-12-21T06:34:34.953567Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = {\n",
    "    'id': [1, 1, 1, 3, 5, 6, 7, 8, 9, 10],\n",
    "    'name': ['a', 'a', 'a', 'c', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "}\n",
    "data2 = {\n",
    "    'id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'age': [21, 11, 45, 11, 56, 22, 26, 26, 17, 32],\n",
    "    'gender': ['M', 'M', 'f', 'f', 'M', 'f', 'M', 'M', 'f', 'M']\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1\n",
    "df1.set_index('id', inplace=True)\n",
    "\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2.set_index('id', inplace=True)\n",
    "df2\n",
    "#df1['gender'] = df2['gender']\n",
    "\n",
    "df = df1.merge(df2, left_index=True, right_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T06:47:16.041758Z",
     "start_time": "2019-12-21T06:47:16.019976Z"
    }
   },
   "outputs": [],
   "source": [
    "dict1 = {\n",
    "    \"Column1\": [\n",
    "        \"A1-19\", \"B2-52\", \"C3-1245Â¯main_123456789\", \"D4\", \"Z89028\",\n",
    "        \"F7Â¯main_123456789\"\n",
    "    ]\n",
    "}\n",
    "df1 = pd.DataFrame(dict1)\n",
    "df1\n",
    "df1['Column1'].str.split('Â¯main_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T06:46:20.206348Z",
     "start_time": "2019-12-21T06:46:20.189634Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[\"New\"]=df1['Column1'].str.split('Â¯main_').str[0]\n",
    "df1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57687415/merge-two-dataframe-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T06:52:23.013506Z",
     "start_time": "2019-12-21T06:52:22.838702Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "left = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': np.random.randn(4)})    \n",
    "right = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': np.random.randn(4)})\n",
    "left\n",
    "right\n",
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57780410/join-multiple-columns-into-one-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['column 1', 'column 2', 'column 3'], data = [['17.1 g', np.nan, np.nan], [np.nan, '7.0 g', np.nan], [np.nan, '3.7 g', '0.7 g'], [np.nan, np.nan, '1.7 g'], ['1.1 g', np.nan, '1.0 g']])\n",
    "df \n",
    "df.bfill(axis=1).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join between "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57823020/how-to-concat-between-columns-keeping-sequence-unchanged-in-2-dataframes-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T06:56:38.957510Z",
     "start_time": "2019-12-21T06:56:38.918046Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = {\n",
    "    'index': [0, 1, 2, 3],\n",
    "    '394': ['Recycle Gas', 'TT', 'nan', 'nan'],\n",
    "    'min': ['min', 'date', '2011-03-02 08:00:00', '2011-03-02 08:00:00'],\n",
    "    'FIC-2000': ['20K20', 'kg/h', '-20.7', '-27.5 ']\n",
    "}\n",
    "data2 = {\n",
    "    'index': [0],\n",
    "    'Unnamed:0': ['Service'],\n",
    "    '0': ['Prop'],\n",
    "    '1': ['Prop1'],\n",
    "    '394': 'Recycle Gas',\n",
    "    '395': ['RecG']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "df1\n",
    "df2\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.filter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T07:00:38.857852Z",
     "start_time": "2019-12-21T07:00:38.838844Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
    "                  index=['mouse', 'rabbit'],\n",
    "                  columns=['one', 'two', 'three'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T07:00:52.211236Z",
     "start_time": "2019-12-21T07:00:52.192299Z"
    }
   },
   "outputs": [],
   "source": [
    "df.filter(items=['one', 'three'])\n",
    "df.filter(regex='e$', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df[col_name].mask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57806725/converting-an-empty-row-into-a-columns-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T07:02:22.214401Z",
     "start_time": "2019-12-21T07:02:20.844344Z"
    }
   },
   "outputs": [],
   "source": [
    "x_df = pd.DataFrame({'A':['John','ex1','ex2','Joe','qz1','qz2','qz3'],\n",
    "                 'val1':[ '',10,5,'',80,10,10],\n",
    "                  'val2':[ '',20,6,'',90,10,1],\n",
    "                  'val3':[ '',30,7,'',100,10,0]})\n",
    "#x_df.loc[:,'val1':'val3'].apply(lambda row: row == '').any(1) \n",
    "\n",
    "#x_df.filter(like='val').ne('').any(1)\n",
    "\n",
    "s = x_df.filter(like='val').ne('').any(1)\n",
    "x_df['A'].mask(s)\n",
    "# mask(s) selects the empty rows\n",
    "x_df['name'] = x_df['A'].mask(s).ffill()\n",
    "x_df\n",
    "# filter\n",
    "x_df[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.index` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/57121550/finding-the-best-match-for-similar-texts-and-keeping-only-unique-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Project_Name\": [\"Hilton International\", \"Hilton International A\"]}\n",
    "df2 = pd.DataFrame(data)\n",
    "df2.index = range(552, 554)\n",
    "for i in df2.index:\n",
    "    df2.loc[[i]][\"Project_Name\"]\n",
    "\n",
    "#df2.loc[[553]] = \"Hilton International\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.apply` `lambda`\n",
    "https://stackoverflow.com/questions/57551081/elegant-way-to-format-datetime-values-without-using-datetime-functions-in-pandas#57551081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2time(x):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(x, '%m/%d/%Y %H:%M:%S %p')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "df1_new['obs_date'] = df1_new['obs_date'].apply(str2time)\n",
    "print(df1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:21:20.235195Z",
     "start_time": "2019-12-30T13:21:20.193504Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Month':[1,1,2,2], 'Year':[2013, 2013, 2013, 2013]})\n",
    "df\n",
    "\n",
    "df['Date'] =  df.apply(lambda row: '1' + '/' + str(row.Month) + '/'+ str(row.Year), axis = 1)\n",
    "print(df.to_string(index=False))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from haversine import haversine\n",
    "x = {'city':['AUSTRALIAN NATIONAL UNIVERSITY', 'BARTON', 'DARWIN', 'DARWIN', 'PARAP', 'ALAWA', 'BRINKIN', 'CASUARINA', 'JINGILI', 'LEE_POINT' ]}\n",
    "la = {'Latitude':[-35.277272,-35.201372, -12.801028 , -12.801028, -12.432181, -12.378451, -12.367769, -12.376597, -12.385761, -12.360865]}\n",
    "lo = {'Longitude':[149.117136,149.095065, 130.955789 , 130.955789, 130.843310,  130.877014, 130.869808, 130.850489, 130.873726, 130.891349]}\n",
    "data = {**x, **la, **lo}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop_duplicates()\n",
    "city = list(df[\"city\"])\n",
    "TwoCity = list(itertools.combinations(city, 2))\n",
    "df1 = pd.DataFrame({'TwoCity':TwoCity})\n",
    "#df['Date'] =  df.apply(lambda row: '1' + '/' + str(row.Month) + '/'+ str(row.Year), axis = 1)\n",
    "df1['Distance'] = df1.apply(lambda row: \\\n",
    "          haversine((df[df['city']==row.TwoCity[0]]['Latitude'], df[df['city']==row.TwoCity[0]]['Longitude']),\\\n",
    "                    (df[df['city']==row.TwoCity[1]]['Latitude'], df[df['city']==row.TwoCity[1]]['Longitude'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'description': ['XG154LU', '4562689', '556', 'LE896E', '65KKL4']}\n",
    "def convert(v):\n",
    "    if any([char.isalpha() for char in v]):\n",
    "        va = [char for char in v if char.isalpha()]\n",
    "        va = ''.join(va)\n",
    "        return va\n",
    "    else:\n",
    "        return v\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "df['description'] = df['description'].apply(convert)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57789813/how-to-avoid-20-if-statements-when-applying-function-to-pandas-based-on-a-city/57790298#57789813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'name': ['jim', 'jon'],\n",
    "    'city': ['new york', ''],\n",
    "    'county': ['', 'los angeles']\n",
    "})\n",
    "\n",
    "df['region'] = df['city'] + df['county']\n",
    "table = {\n",
    "    'new york': 'abc123',\n",
    "    'chicago': 'abc124',\n",
    "    'los angeles': 'abc125',\n",
    "    'miami': 'abc126'\n",
    "}\n",
    "df['region'] = df.region.apply(lambda row: table[row])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `df.applymap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57517483/how-to-select-rows-within-two-dates-in-a-pandas-dataframe#57517527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T07:29:40.780254Z",
     "start_time": "2019-12-21T07:29:40.536672Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'col1': ['xxx;#2;yyy', 'aaa;#3;bbbccc '],\n",
    "    'col2': ['zzz;#46;zyzcz', 'bbbb;cccc;dd#5']\n",
    "})\n",
    "df\n",
    "\n",
    "\n",
    "def cleanDigit(row):\n",
    "    replacements = [('\\d', ''), ('#', ''), (';;', ';')]\n",
    "    for (old, new) in replacements:\n",
    "        row = re.sub(old, new, row)\n",
    "    return row\n",
    "\n",
    "\n",
    "df[['col1', 'col2']] = df[['col1', 'col2']].applymap(cleanDigit)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T08:29:02.022480Z",
     "start_time": "2019-12-21T08:29:01.992690Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T08:32:15.727974Z",
     "start_time": "2019-12-21T08:32:15.662734Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({\n",
    "    'text': [[['some', 'string'], ['yes']],\n",
    "             [['hello', 'how', 'are', 'u'], ['fine', 'thanks']]],\n",
    "    'names': [[['chris'], ['peter', 'kate']],\n",
    "              [['steve', 'john'], ['kyle', 'eric']]]\n",
    "})\n",
    "\n",
    "df5\n",
    "df5.applymap(lambda x: list(chain.from_iterable(x)))\n",
    "df5.applymap(lambda x: sum(x, []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57107125/remove-duplicates-from-python-dataframe-list#57107125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: list(dict.fromkeys(ast.literal_eval(x)))\n",
    "df['newlist'] = df['text_lemmatized'].map(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df.col_name.str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement it with pandas \n",
    "raw_data = {'ID': [1,2,3,4,5,6,7,8,9,10], 'body': ['FITrnXS$100', '$1000rnReason', 'rnIf', 'bevlauedrnrnnext', 'obccrnrnnoncrnrnactionrn', 'rnrnnotification', 'insdrnrnnon', 'rnrnupdated', 'rnreason', 'rnrnrnLOR']}\n",
    "remove_string =['rn', 'rnr', 'rnrn', 'rnrnrn']\n",
    "df = pd.DataFrame(raw_data, columns = ['ID', 'body', 'cleaned_txt', 'Removed_string'])\n",
    "df \n",
    "df['cleaned_txt'], df['Removed_string'] = df['body'], df['body']\n",
    "for i in remove_string[::-1]:\n",
    "    df['cleaned_txt'] = df['cleaned_txt'].str.replace(i, ' ')\n",
    "    df[i] = df['Removed_string'].str.extract('({})'.format(i)) \n",
    "\n",
    "df['Removed_string'] = df[remove_string].ffill(axis=1).iloc[:, -1]\n",
    "df = df.drop(remove_string, axis=1)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement it in original data ðŸ‘Œ\n",
    "raw_data = {'ID': [1,2,3,4,5,6,7,8,9,10], \n",
    "        'body': ['FITrnXS$100', '$1000rnReason', 'rnIf', 'bevlauedrnrnnext', 'obccrnrnnoncrnrnactionrn', 'rnrnnotification', 'insdrnrnnon', 'rnrnupdated', 'rnreason', 'rnrnrnLOR']}\n",
    "removed_string =['rn', 'rnr', 'rnrn', 'rnrnrn']\n",
    "removed_string =  removed_string[::-1]\n",
    "\n",
    "raw_data['Removed_string'] = []\n",
    "raw_data['cleaned_txt'] = []\n",
    "for i in raw_data['body']:\n",
    "    j = 0\n",
    "    m = removed_string[j]\n",
    "    while True:\n",
    "        m = removed_string[j]\n",
    "        pattern = re.compile(m)\n",
    "        n = pattern.findall(i)\n",
    "        if len(n) != 0: \n",
    "            raw_data['cleaned_txt'].append(i.replace(m, ' '))\n",
    "            raw_data['Removed_string'].append(m)\n",
    "            break\n",
    "        j += 1\n",
    "df = pd.DataFrame(raw_data, columns = ['ID', 'body', 'cleaned_txt', 'Removed_string'])\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## len().value_count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\":[\"a\", \"b\", \"aa\", \"aaa\", \"bbb\", \"a\"]})\n",
    "df.id.str.len().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge  drop duplication \n",
    "https://stackoverflow.com/questions/57406428/pandas-merge-df-many-to-many-without-duplicates/57406653#57406653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {\n",
    "    \"a\": [0,0,1,2],\n",
    "    \"b\": [3,3,4,5],\n",
    "    \"c\": [6,7,8,9]\n",
    "}\n",
    "df1 = pd.DataFrame(data_dic)\n",
    "\n",
    "data_dic = {\n",
    "    \"a\": [0,0,1,2],\n",
    "    \"b\": [3,3,4,5],\n",
    "    \"d\": [10,10,12,13]\n",
    "}\n",
    "df2 = pd.DataFrame(data_dic)\n",
    "\n",
    "\n",
    "df3 = pd.merge(df1, df2, how='inner', on=['a', 'b']).drop_duplicates()\n",
    "df3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([df1, df2], axis=1).T.drop_duplicates().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57604212/how-to-split-a-list-of-dictionaries-into-multiple-columns-keeping-the-same-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `df.explode`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53218931/how-to-unnest-explode-a-column-in-a-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'score': [1,2,3], \n",
    "        'tags': [['apple','pear','guava'],['truck','car','plane'],['cat','dog','mouse']]}\n",
    "df = pd.DataFrame(raw_data, columns = ['score', 'tags'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "for i in raw_data['tags']:\n",
    "    for j in i:\n",
    "        k.append(j )\n",
    "k \n",
    "raw_data['tags'] = k \n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dictionary or list inside a column into separate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57800262/convert-a-column-with-a-list-of-dicts-where-column-name-and-value-are-both-pres/57800449?noredirect=1#comment102033530_57800449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col1':100, 'col2': 200, 'col3': [{'attribute': 'Pattern', 'value': 'Printed'},\n",
    " {'attribute': 'Topwear style', 'value': 'T shirt'},\n",
    " {'attribute': 'Bottomwear Length', 'value': 'Short'},\n",
    " {'attribute': 'Colour Palette', 'value': 'Bright colours'},\n",
    " {'attribute': 'Bottomwear style', 'value': 'Baggy'},\n",
    " {'attribute': 'Topwear length', 'value': 'Waist'},\n",
    " {'attribute': 'Sleeve style', 'value': 'Sleeveless'},\n",
    " {'attribute': 'Type of pattern', 'value': 'Graphic print'},\n",
    " {'attribute': 'Neck', 'value': 'Round'},\n",
    " {'attribute': 'Level of embellishment', 'value': 'No'}]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "x = df['col3'].tolist()\n",
    "newcol = {item['attribute'] : [item['value']] for item in x }\n",
    "newdf = pd.DataFrame(newcol)\n",
    "del df['col3'] \n",
    "print(df.join(newdf, how='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `groupby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T13:12:06.227960Z",
     "start_time": "2019-12-27T13:12:06.223375Z"
    }
   },
   "source": [
    "* https://stackoverflow.com/questions/59501259/pandas-cumulative-count-on-new-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T13:36:44.433499Z",
     "start_time": "2019-12-27T13:36:44.424508Z"
    }
   },
   "outputs": [],
   "source": [
    "labels, uniques = pd.factorize(['a', 'c', 'a', 'b'], sort=True)\n",
    "labels\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T13:14:37.421135Z",
     "start_time": "2019-12-27T13:14:37.391722Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['col_1'] = [1, 1, 1, 2, 2, 2, 3, 3, 3]\n",
    "df['col_2'] = ['A', 'B', 'B', 'A', 'B', 'C', 'A', 'A', 'B']\n",
    "df['col_3'] = df.groupby('col_1')['col_2'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.geeksforgeeks.org/adding-new-column-to-existing-dataframe-in-pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```md\n",
    "datetime               transmission #\n",
    "2019-07-12 00:03:06    124\n",
    "2019-07-12 00:04:56    124\n",
    "2019-07-12 00:20:10    125\n",
    "2019-07-12 00:21:33    125\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'testid': 'testid_1', 'value':15},\n",
    "{'testid': 'testid_1', 'value':15},\n",
    "{'testid': 'testid_1', 'value':20},\n",
    "{'testid': 'testid_1', 'value':20},\n",
    "{'testid': 'testid_1', 'value':15},\n",
    "{'testid': 'testid_1', 'value':15},\n",
    "{'testid': 'testid_2', 'value':215},\n",
    "{'testid': 'testid_2', 'value':215},\n",
    "{'testid': 'testid_3', 'value':215},\n",
    "{'testid': 'testid_3', 'value':69},\n",
    "{'testid': 'testid_3', 'value':215}]\n",
    "\n",
    "df = pd.DataFrame(data) \n",
    "df \n",
    "df['newid']=df.groupby('testid').value.apply(lambda x : x.diff().ne(0).cumsum()) \n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57802242/python-group-by-column-and-select-by-hierarchy#57802362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col-a':[1,1,1,2,2,3,3],'col-b': [None, 'Failed', 'Passed', 'None', 'Passed', 'Inconclusive', 'Passed']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "d = {'Failed':0,'Inconclusive':1, 'Passed':2, None: 3}\n",
    "df['new'] = df['col-b'].map(d)\n",
    "df = df.sort_values(['col-a', 'new']).drop_duplicates('col-a').drop('new', 1)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57829530/how-to-split-the-csv-based-on-multiple-columns#57829530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Header1': ['Alpha', 'Alpha', 'Beta', 'Beta', 'Beta', 'Gamma'],\n",
    "    'Header2': [\n",
    "        'energy', 'energy', 'energy_imbalance', 'energy', 'energy',\n",
    "        'energy_imbalance'\n",
    "    ],\n",
    "    'Header3': [0.1, 0.34, 0.66, 0.7, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df \n",
    "\n",
    "list(df.groupby(['Header1','Header2']))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57843241/how-to-create-a-new-column-based-on-condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col1':[1,1,1,2,2,3,3,3], 'col2':['C','B','A','C','C','A','C','B']}\n",
    "df = pd.DataFrame(data)\n",
    "df['col2'].eq('A').groupby(df['col1']).transform('any')\n",
    "df['col3']=df['col2'].eq('A').groupby(df['col1']).transform('any').map({True:'T', False:'F'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `diff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([11,15,22,27,36,69,77])\n",
    "s.diff().fillna(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.Series.dt.total_seconds`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57814695/formating-time-difference-in-dataframe-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'request': ['REQ0079455', 'REQ0079455'],\n",
    "    'Req_Created': ['15/05/2019  16:51', '15/05/2019 16:51'],\n",
    "    'Req_Closed': ['23/05/2019 20:53', '23/05/2019 20:53']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n",
    "df['Req_time_taken'] = pd.to_datetime(\n",
    "    df['Req_Closed'], format='%d/%m/%Y %H:%M') - pd.to_datetime(\n",
    "        df['Req_Created'], format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Req_time_taken'].dt.total_seconds().apply(lambda x: '%s hours %s minutes' %\n",
    "                                              (x // 3600, x % 3600 / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57822431/duplicate-rows-in-a-value-range-of-a-dataframe#57822485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pd.series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T14:03:38.169840Z",
     "start_time": "2019-12-27T14:03:38.146487Z"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(range(3))\n",
    "s.transform([np.sqrt, np.exp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"col1\" : [\"a\", \"b\", \"z\",\"w\", \"g\", \"p\", \"f\"], \"col2\" : \n",
    "[\"010\", \"030\",\"500\",\"333\",\"090\",\"050\",\"111\"]})\n",
    "data['col2'] = data['col2'].apply(lambda x:re.sub(r\"^0\", '', x))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57509388/how-to-extract-value-from-an-array-based-on-condition-in-pandas-or-numpy#57509518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Bird':['Parrot','Eagle','Seagull'],'Color':[['Light_Blue','Green','Dark_Blue'],['Sky_Blue','Black','White', 'Yellow','Gray'],['White','Jet_Blue','Pink', 'Tan','Brown', 'Purple']]}\n",
    "df =pd.DataFrame( data) \n",
    "df[\"Blue\"]=df.Color.apply(lambda x: [v for v in x if \"Blue\" not in v])\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57549300/extract-limited-set-of-date-patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "data = pd.DataFrame({\"col1\" : [\"a\", \"b\", \"z\",\"w\", \"g\", \"p\", \"f\"], \"col2\" : \n",
    "[\"010\", \"030\",\"500\",\"333\",\"090\",\"050\",\"111\"]})\n",
    "data.head(2)\n",
    "\n",
    "pattern =  re.compile(r'^0+')\n",
    "for i, v in enumerate(data[\"col2\"]):\n",
    "    data[\"col2\"][i]=pattern.sub(\"\", v)  \n",
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'color':[['Light_Blue','Green','Dark_Blue'], ['Sky_Blue','Black','White', 'Yellow','Gray'],['White','Jet_Blue','Pink', 'Tan','Brown', 'Purple']]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "[[i for i in r if not i.endswith(tuple(['_Blue', '_']))] for r in df.color]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57808480/how-to-apply-the-regex-on-pandas-dataframe-column-having-string-representation-o#57808565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.color.apply(lambda row: [x for x in row if not x.endswith(tuple(['_Blue', '_']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/57263555/dataframe-resample-does-not-include-last-datam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2020-01-01',  periods=12, freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Date':['2020-01-01', '2021-01-01', '2022-01-01', '2023-01-01'],\\\n",
    "                   'Value':[1.248310e+06, 1.259511e+06, 1.276312e+06,1.298714e+06]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range('1/1/2020', periods=4, freq='YS')\n",
    "series = pd.Series([1.248310e+06, 1.259511e+06, 1.276312e+06, 1.298714e+06], index=index)\n",
    "series2 = pd.Series(1.298714e+06, pd.date_range('12/1/2023', periods=1))\n",
    "series = series.append(series2)\n",
    "down_sampling = series.resample('MS').ffill()\n",
    "down_sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/57507399/how-to-divide-60-mins-datapoints-into-15-mins#57507518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Time' :['2016-01-01 00:00:00','2016-01-01 01:00:00','2016-01-01 02:00:00 '], 'A':[1,5,13]})\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range('2016-01-01 00:00:00', periods=4, freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Time': [\"2016-01-01 00:00:00\", \"2016-01-01 01:00:00\", \"2016-01-01 02:00:00\"],\n",
    "    'A': [1 , 5, 13]\n",
    "})\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "new_idx = pd.DatetimeIndex(start=df['Time'].iloc[0], end=df['Time'].iloc[-1], freq='15min')\n",
    "df2 = df.set_index('Time').reindex(new_idx).interpolate().reset_index()\n",
    "df2.rename(columns={'index': 'Time'}, inplace=True)\n",
    "df2['A'] = df2['A'].round().astype(int)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['temp'] = pd.date_range(start='01-Jan-2000', end='31-Dec-2018', freq='MS')  \n",
    "df['value'] = 5\n",
    "df.set_index('temp', inplace=True)\n",
    "df['days_in_month'] = df.index.daysinmonth \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to save styled pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Diego', 'Luis', 'Vidal', 'John', 'Yusef']\n",
    "id = ['b000000005', 'b000000015', 'b000000002', 'b000000011', 'b000000013']\n",
    "cel = [7878, 6464, 1100, 4545, 1717]\n",
    "date = pd.to_datetime(['2017-05-31 20:53:00', '2017-05-11 20:53:00', '2017-05-08 20:53:00', \n",
    "                       '2017-06-06 20:53:00', '2017-06-06 20:53:00'])\n",
    "\n",
    "df = pd.DataFrame({'Name':name,'ID':id,'Cel':cel,'Date':date})\n",
    "\n",
    "def color(val):\n",
    "    if val < datetime.now():\n",
    "        color = 'green'\n",
    "    elif val > datetime.now():\n",
    "        color = 'yellow'\n",
    "    elif val > (datetime.now() + timedelta(days=60)):\n",
    "        color = 'red'\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "df = df.style.applymap(color, subset=['Date'])\n",
    "# https://mode.com/example-gallery/python_dataframe_styling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.apply(borders) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html = df.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataFrame.html', 'a') as f:\n",
    "    f.write(df.render() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "176.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
